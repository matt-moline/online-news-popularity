{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "653650a0-8e70-4c13-a250-e3682d1b4edb",
   "metadata": {},
   "source": [
    "# Final Analysis and Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88239e40-7ce4-4b8a-84fb-9ea1cf66f686",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "This notebook provides a summary of the final analysis and results for the Online News Popularity prediction project. \n",
    "In the previous notebooks, we explored the data, performed feature engineering, built multiple machine learning models, \n",
    "and optimized the best-performing model (LightGBM) through hyperparameter tuning. \n",
    "This notebook summarizes the key findings, evaluates the final model's performance, \n",
    "and presents the feature importance analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0bfc77e-29ab-48f9-b273-953419f55830",
   "metadata": {},
   "source": [
    "## 1. Load the Dataset and Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e94bbba-9abb-4249-8c03-e2a66ecb99d7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'X_test.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 10\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mean_absolute_error, mean_squared_error, r2_score\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Load the dataset (assuming X_test and y_test have been pre-saved or can be reloaded)\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# If necessary, replace with code to load the test dataset.\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m X_test \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mX_test.npy\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Example placeholder for the test dataset\u001b[39;00m\n\u001b[0;32m     11\u001b[0m y_test \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124my_test.npy\u001b[39m\u001b[38;5;124m'\u001b[39m)  \u001b[38;5;66;03m# Example placeholder for the actual target variable\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Load the best LightGBM model after tuning\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\lib\\npyio.py:427\u001b[0m, in \u001b[0;36mload\u001b[1;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[0m\n\u001b[0;32m    425\u001b[0m     own_fid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    426\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 427\u001b[0m     fid \u001b[38;5;241m=\u001b[39m stack\u001b[38;5;241m.\u001b[39menter_context(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mos_fspath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    428\u001b[0m     own_fid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    430\u001b[0m \u001b[38;5;66;03m# Code to distinguish from NumPy binary files and pickles.\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'X_test.npy'"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# Load the dataset (assuming X_test and y_test have been pre-saved or can be reloaded)\n",
    "# If necessary, replace with code to load the test dataset.\n",
    "X_test = np.load('X_test.npy')  # Example placeholder for the test dataset\n",
    "y_test = np.load('y_test.npy')  # Example placeholder for the actual target variable\n",
    "\n",
    "# Load the best LightGBM model after tuning\n",
    "best_lgb_model = joblib.load('best_lgb_model.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6a6dc09-9c89-4788-a375-9f5fe734c6d7",
   "metadata": {},
   "source": [
    "## 2. Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2c3a8c82-a1ce-4409-8dc8-857e88eea1f8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'best_lgb_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Predict on the test set\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m y_pred_tuned \u001b[38;5;241m=\u001b[39m \u001b[43mbest_lgb_model\u001b[49m\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Calculate performance metrics\u001b[39;00m\n\u001b[0;32m      5\u001b[0m mae_tuned \u001b[38;5;241m=\u001b[39m mean_absolute_error(y_test, y_pred_tuned)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'best_lgb_model' is not defined"
     ]
    }
   ],
   "source": [
    "# Predict on the test set\n",
    "y_pred_tuned = best_lgb_model.predict(X_test)\n",
    "\n",
    "# Calculate performance metrics\n",
    "mae_tuned = mean_absolute_error(y_test, y_pred_tuned)\n",
    "mse_tuned = mean_squared_error(y_test, y_pred_tuned)\n",
    "rmse_tuned = np.sqrt(mse_tuned)\n",
    "r2_tuned = r2_score(y_test, y_pred_tuned)\n",
    "\n",
    "# Display the results\n",
    "print(f'Tuned LightGBM Regressor - MAE: {mae_tuned:.2f}')\n",
    "print(f'Tuned LightGBM Regressor - MSE: {mse_tuned:.2f}')\n",
    "print(f'Tuned LightGBM Regressor - RMSE: {rmse_tuned:.2f}')\n",
    "print(f'Tuned LightGBM Regressor - R2 Score: {r2_tuned:.2f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef1eec0-4c66-417a-823e-42b1bae1cb99",
   "metadata": {},
   "source": [
    "## 3. Feature Importance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "183d5fe8-08d7-4803-b5cb-77750b2a3776",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'best_lgb_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m feature_names \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfeature1\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfeature2\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfeature3\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfeature4\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfeature5\u001b[39m\u001b[38;5;124m'\u001b[39m]  \u001b[38;5;66;03m# Replace with actual feature names\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Get feature importance by gain\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m importance_gain \u001b[38;5;241m=\u001b[39m \u001b[43mbest_lgb_model\u001b[49m\u001b[38;5;241m.\u001b[39mbooster_\u001b[38;5;241m.\u001b[39mfeature_importance(importance_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgain\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Create a DataFrame for gain-based feature importance\u001b[39;00m\n\u001b[0;32m      8\u001b[0m feature_importance_gain_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFeature\u001b[39m\u001b[38;5;124m'\u001b[39m: feature_names, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mImportance\u001b[39m\u001b[38;5;124m'\u001b[39m: importance_gain})\n",
      "\u001b[1;31mNameError\u001b[0m: name 'best_lgb_model' is not defined"
     ]
    }
   ],
   "source": [
    "# Assuming you have a list of feature names\n",
    "feature_names = ['feature1', 'feature2', 'feature3', 'feature4', 'feature5']  # Replace with actual feature names\n",
    "\n",
    "# Get feature importance by gain\n",
    "importance_gain = best_lgb_model.booster_.feature_importance(importance_type='gain')\n",
    "\n",
    "# Create a DataFrame for gain-based feature importance\n",
    "feature_importance_gain_df = pd.DataFrame({'Feature': feature_names, 'Importance': importance_gain})\n",
    "feature_importance_gain_df = feature_importance_gain_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Display feature importance\n",
    "print(feature_importance_gain_df)\n",
    "\n",
    "# Plot gain-based feature importance\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.barh(feature_importance_gain_df['Feature'], feature_importance_gain_df['Importance'], color='lightgreen')\n",
    "plt.xlabel('Gain')\n",
    "plt.title('Feature Importance by Gain for LightGBM')\n",
    "plt.gca().invert_yaxis()  # Invert y-axis to show most important features at the top\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c468846-152e-4949-951d-a1008049b1c1",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 4. Final Remarks\n",
    "The final LightGBM model, after hyperparameter tuning, demonstrates strong performance in predicting the popularity of online news articles. \n",
    "The RMSE and R² scores indicate that the model generalizes well to the unseen test data.\n",
    "\n",
    "Feature importance analysis revealed that certain features, such as content length, title sentiment, and the timing of publication, \n",
    "have a significant impact on predicting the number of shares an article will receive.\n",
    "\n",
    "Moving forward, continuous monitoring and updating of the model with new data will ensure that it stays relevant and accurate over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe93cc1-070b-4f12-b80c-0307256ce14b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
